{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "\r\n",
    "# Table of Contents\r\n",
    "\r\n",
    "### Load Python Packages\r\n",
    "### Download Data\r\n",
    "### Preprocess Data\r\n",
    "### Problem Definition\r\n",
    "### Build Environment\r\n",
    "### Implement DRL Algorithms\r\n",
    "### Backtesting Performance\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import sys\r\n",
    "sys.path.append(\"FinRL-Library\")\r\n",
    "\r\n",
    "from finrl.plot import backtest_stats, backtest_plot, get_daily_return, get_baseline\r\n",
    "from finrl.neo_finrl.data_processor import DataProcessor\r\n",
    "from finrl.drl_agents.rllib.models import DRLAgent as DRLAgent_rllib\r\n",
    "from finrl.drl_agents.stablebaselines3.models import DRLAgent\r\n",
    "from finrl.neo_finrl.env_stock_trading.env_stocktrading_np import StockTradingEnv as StockTradingEnv_numpy\r\n",
    "from finrl.neo_finrl.env_stock_trading.env_stocktrading import StockTradingEnv\r\n",
    "from finrl.neo_finrl.preprocessor.preprocessors import FeatureEngineer, data_split\r\n",
    "from finrl.neo_finrl.preprocessor.yahoodownloader import YahooDownloader\r\n",
    "from finrl.apps import config\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Open AI gym<br />\r\n",
    "## https://gym.openai.com <br />\r\n",
    "<br />\r\n",
    "\r\n",
    "# German Aerospace Center (DLR) - Institute of Robotics and Mechatronics (RM)<br />\r\n",
    "## Stable Baseline<br />\r\n",
    "<br />\r\n",
    "\r\n",
    "# AI4Finance Foundation<br />\r\n",
    "## Financial Feature engineering and algorithems<br />"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import matplotlib\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import datetime\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import gym\r\n",
    "from gym import spaces\r\n",
    "from gym.utils import seeding\r\n",
    "from copy import deepcopy\r\n",
    "import pickle\r\n",
    "\r\n",
    "matplotlib.use(\"Agg\")\r\n",
    "\r\n",
    "from torch.nn import Softsign, ReLU\r\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, SubprocVecEnv\r\n",
    "from stable_baselines3.common import logger\r\n",
    "\r\n",
    "import multiprocessing\r\n",
    "\r\n",
    "import os\r\n",
    "if not os.path.exists(\"./\" + config.DATA_SAVE_DIR):\r\n",
    "    os.makedirs(\"./\" + config.DATA_SAVE_DIR)\r\n",
    "if not os.path.exists(\"./\" + config.TRAINED_MODEL_DIR):\r\n",
    "    os.makedirs(\"./\" + config.TRAINED_MODEL_DIR)\r\n",
    "if not os.path.exists(\"./\" + config.TENSORBOARD_LOG_DIR):\r\n",
    "    os.makedirs(\"./\" + config.TENSORBOARD_LOG_DIR)\r\n",
    "if not os.path.exists(\"./\" + config.RESULTS_DIR):\r\n",
    "    os.makedirs(\"./\" + config.RESULTS_DIR)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df = YahooDownloader(start_date = '2009-01-01',\r\n",
    "                     end_date = '2021-08-01',\r\n",
    "                     ticker_list = config.DOW_30_TICKER).fetch_data()\r\n",
    "df.sort_values(['date','tic'],ignore_index=True).head()"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fe = FeatureEngineer(\r\n",
    "                    use_technical_indicator=True,\r\n",
    "                    tech_indicator_list = config.TECHNICAL_INDICATORS_LIST,\r\n",
    "                    use_turbulence=True,\r\n",
    "                    user_defined_feature = False)\r\n",
    "\r\n",
    "processed = fe.preprocess_data(df)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "processed.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "train = data_split(processed, '2009-01-01','2019-01-01')\r\n",
    "trade = data_split(processed, '2019-01-01','2021-06-01')\r\n",
    "print(len(train))\r\n",
    "print(len(trade))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Defining the problem statement:\r\n",
    "\r\n",
    "Action : Buy / Sell / Hold   <br />a : $\\epsilon${1,-1,0}\r\n",
    "\r\n",
    "<br /> hmax = 10\r\n",
    "\r\n",
    "<br />a : $\\epsilon${-10,0,10}\r\n",
    "\r\n",
    "<br />\r\n",
    "state space : total stocks in set * unique time steps * action\r\n",
    "\r\n",
    "what are we trying to optimize:\r\n",
    "<br />\r\n",
    "portfolio value = $100 <br/>\r\n",
    "\r\n",
    "p(v) = v_{t+1} - v_{t}"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class StockTradingEnvV2(gym.Env):\r\n",
    "\r\n",
    "\r\n",
    "    \"\"\"\r\n",
    "    Creating a stock trading environment from OpenAI gym\r\n",
    "    Parameters:\r\n",
    "    state space: {start_cash, <owned_shares>, for s in stocks{<stock.values>}, }\r\n",
    "        df (pandas.DataFrame): Dataframe containing data\r\n",
    "        transaction_cost (float): commission paid for each transaction\r\n",
    "        hmax (int): max number of share purchases allowed per asset\r\n",
    "        turbulence_threshold (float): Maximum turbulence allowed in market for purchases to occur. If exceeded, positions are liquidated\r\n",
    "        print_verbosity(int): When iterating (step), how often to print stats about state of env\r\n",
    "        reward_scaling (float): Scaling value to multiply reward by at each step.\r\n",
    "        initial_amount: (int, float): Principal cash amount to start with\r\n",
    "        daily_information_columns (list(str)): Columns to use when building state space from the dataframe.\r\n",
    "        out_of_cash_penalty (int, float): Penalty to apply if the algorithm runs out of cash\r\n",
    "\r\n",
    "\r\n",
    "    tests:\r\n",
    "        after reset, static strategy should result in same metrics\r\n",
    "\r\n",
    "        buy zero should result in no costs, no assets purchased\r\n",
    "        given no change in prices, no change in asset values\r\n",
    "    \"\"\"\r\n",
    "    metadata = {\"render.modes\": [\"human\"]}\r\n",
    "\r\n",
    "    def __init__(\r\n",
    "        self,\r\n",
    "        df,\r\n",
    "        transaction_cost_pct=3e-3,\r\n",
    "        date_col_name=\"date\",\r\n",
    "        hmax=10,\r\n",
    "        turbulence_threshold=None,\r\n",
    "        print_verbosity=10,\r\n",
    "        reward_scaling=1e-4,\r\n",
    "        initial_amount=1e6,\r\n",
    "        daily_information_cols=[\"open\", \"close\", \"high\", \"low\", \"volume\"],\r\n",
    "        out_of_cash_penalty=None,\r\n",
    "        cache_indicator_data = True\r\n",
    "    ):\r\n",
    "        self.df = df\r\n",
    "        self.stock_col = \"tic\"\r\n",
    "        self.assets = df[self.stock_col].unique()\r\n",
    "        self.dates = df[date_col_name].sort_values().unique()\r\n",
    "        self.df = self.df.set_index(date_col_name)\r\n",
    "        self.hmax = hmax\r\n",
    "        self.initial_amount = initial_amount\r\n",
    "        if out_of_cash_penalty is None:\r\n",
    "            out_of_cash_penalty=-initial_amount*0.5\r\n",
    "        self.out_of_cash_penalty = out_of_cash_penalty\r\n",
    "        self.print_verbosity = print_verbosity\r\n",
    "        self.transaction_cost_pct = transaction_cost_pct\r\n",
    "        self.reward_scaling = reward_scaling\r\n",
    "        self.daily_information_cols = daily_information_cols\r\n",
    "        self.close_index = self.daily_information_cols.index(\"close\")\r\n",
    "        self.state_space = (\r\n",
    "            1 + len(self.assets) + len(self.assets) * len(self.daily_information_cols)\r\n",
    "        )\r\n",
    "        self.action_space = spaces.Box(low=-1, high=1, shape=(len(self.assets),))\r\n",
    "        self.observation_space = spaces.Box(\r\n",
    "            low=-np.inf, high=np.inf, shape=(self.state_space,)\r\n",
    "        )\r\n",
    "        self.episode = -1  # initialize so we can call reset\r\n",
    "        self.seed()\r\n",
    "        self.episode_history = []\r\n",
    "        self.printed_header = False\r\n",
    "        self.cache_indicator_data = cache_indicator_data\r\n",
    "        self.cached_data = None\r\n",
    "        if self.cache_indicator_data:\r\n",
    "            print(\"caching data\")\r\n",
    "            self.cached_data = [self.get_date_vector(i) for i, _ in enumerate(self.dates)]\r\n",
    "            print(\"data cached!\")\r\n",
    "        \r\n",
    "\r\n",
    "    def seed(self):\r\n",
    "        pass\r\n",
    "\r\n",
    "\r\n",
    "    def reset(self):\r\n",
    "        self.sum_trades = 0\r\n",
    "        self.date_index = 0\r\n",
    "        self.episode += 1\r\n",
    "        self.actions_memory = []\r\n",
    "        self.state_memory = []\r\n",
    "        self.account_information = {\r\n",
    "            \"cash\": [],\r\n",
    "            \"asset_value\": [],\r\n",
    "            \"total_assets\": [],\r\n",
    "            'reward': []\r\n",
    "        }\r\n",
    "        self.state_memory.append(\r\n",
    "            np.array(\r\n",
    "                [self.initial_amount]\r\n",
    "                + [0] * len(self.assets)\r\n",
    "                + self.get_date_vector(self.date_index)\r\n",
    "            )\r\n",
    "        )\r\n",
    "        return [0 for _ in range(self.state_space)]\r\n",
    "\r\n",
    "    def get_date_vector(self, date, cols=None):\r\n",
    "        if (cols is None) and (self.cached_data is not None):\r\n",
    "            return self.cached_data[date]\r\n",
    "        else:\r\n",
    "            date = self.dates[date]\r\n",
    "            if cols is None:\r\n",
    "                cols = self.daily_information_cols\r\n",
    "            trunc_df = self.df.loc[date]\r\n",
    "            v = []\r\n",
    "            for a in self.assets:\r\n",
    "                subset = trunc_df[trunc_df[self.stock_col] == a]\r\n",
    "                v += subset.loc[date, cols].tolist()\r\n",
    "            assert len(v) == len(self.assets) * len(cols)\r\n",
    "            return v\r\n",
    "    \r\n",
    "    def log_step(self, reason, terminal_reward=None):\r\n",
    "        if terminal_reward is None:\r\n",
    "            terminal_reward = self.account_information['reward'][-1]\r\n",
    "        cash_pct = self.account_information['cash'][-1]/self.account_information['total_assets'][-1]\r\n",
    "        rec = [self.episode, self.date_index, reason, f\"${int(self.account_information['total_assets'][-1])}\",f\"${terminal_reward:0.2f}\", f\"{cash_pct*100:0.2f}%\"]\r\n",
    "\r\n",
    "        self.episode_history.append(rec)\r\n",
    "        print(self.template.format(*rec))\r\n",
    "\r\n",
    "    def step(self, actions):\r\n",
    "        #print header only first time\r\n",
    "        if self.printed_header is False:\r\n",
    "            self.template = \"{0:8}|{1:10}|{2:15}|{3:7}|{4:10}|{5:10}\" # column widths: 8, 10, 15, 7, 10\r\n",
    "            print(self.template.format(\"EPISODE\", \"STEPS\", \"TERMINAL_REASON\", \"TOT_ASSETS\", \"TERMINAL_REWARD_unsc\", \"CASH_PCT\"))\r\n",
    "            self.printed_header = True\r\n",
    "\r\n",
    "        # define terminal function in scope so we can do something about the cycle being over\r\n",
    "        def return_terminal(reason='Last Date', extra_reward=0):\r\n",
    "\r\n",
    "            state = self.state_memory[-1]\r\n",
    "            reward = 0\r\n",
    "            reward += extra_reward\r\n",
    "            self.log_step(reason = reason, terminal_reward= reward)\r\n",
    "            reward = reward*self.reward_scaling\r\n",
    "            # Add outputs to logger interface\r\n",
    "            reward_pct = self.account_information['total_assets'][-1]/self.initial_amount\r\n",
    "            '''logger.record(\"environment/total_reward_pct\", (reward_pct-1)*100)\r\n",
    "            logger.record(\"environment/daily_trades\", self.sum_trades/self.date_index)\r\n",
    "            logger.record(\"environment/completed_steps\", self.date_index)\r\n",
    "            logger.record(\"environment/sum_rewards\", np.sum(self.account_information['reward']))'''\r\n",
    "            return state, reward, True, {}\r\n",
    "\r\n",
    "        # print if it's time.\r\n",
    "        if (self.date_index + 1) % self.print_verbosity == 0:\r\n",
    "            self.log_step(reason = 'update')\r\n",
    "\r\n",
    "        #if we're at the end\r\n",
    "        if self.date_index == len(self.dates) - 1:\r\n",
    "            #if we hit the end, set reward to total gains (or losses)\r\n",
    "            terminal_reward = self.account_information['total_assets'][-1]-self.initial_amount\r\n",
    "            return return_terminal(extra_reward = terminal_reward)\r\n",
    "        else:\r\n",
    "            begin_cash = self.state_memory[-1][0]\r\n",
    "            holdings = self.state_memory[-1][1 : len(self.assets) + 1]\r\n",
    "            assert (min(holdings)>=0)\r\n",
    "            closings = np.array(self.get_date_vector(self.date_index, cols=[\"close\"]))\r\n",
    "\r\n",
    "            # compute current value of holdings\r\n",
    "            asset_value = np.dot(holdings, closings)\r\n",
    "\r\n",
    "            # reward is (cash + assets) - (cash_last_step + assets_last_step)\r\n",
    "            if self.date_index==0:\r\n",
    "                reward = 0\r\n",
    "            else:\r\n",
    "                reward = (\r\n",
    "                    begin_cash + asset_value - self.account_information[\"total_assets\"][-1]\r\n",
    "                )\r\n",
    "\r\n",
    "            # log the values of cash, assets, and total assets\r\n",
    "            self.account_information[\"cash\"].append(begin_cash)\r\n",
    "            self.account_information[\"asset_value\"].append(asset_value)\r\n",
    "            self.account_information[\"total_assets\"].append(begin_cash + asset_value)\r\n",
    "            self.account_information['reward'].append(reward)\r\n",
    "\r\n",
    "            # multiply action values by our scalar multiplier and save\r\n",
    "            actions = actions * self.hmax\r\n",
    "            self.actions_memory.append(actions)\r\n",
    "\r\n",
    "            # clip actions so we can't sell more assets than we hold\r\n",
    "            actions = np.maximum(actions, -np.array(holdings))\r\n",
    "            self.sum_trades += np.sum(np.abs(actions))\r\n",
    "\r\n",
    "            # compute our proceeds from sales, and add to cash\r\n",
    "            sells = -np.clip(actions, -np.inf, 0)\r\n",
    "            proceeds = np.dot(sells, closings)\r\n",
    "            costs = proceeds * self.transaction_cost_pct\r\n",
    "            coh = begin_cash + proceeds\r\n",
    "\r\n",
    "            # compute the cost of our buys\r\n",
    "            buys = np.clip(actions, 0, np.inf)\r\n",
    "            spend = np.dot(buys, closings)\r\n",
    "            costs += spend * self.transaction_cost_pct\r\n",
    "\r\n",
    "            # if we run out of cash, end the cycle and penalize\r\n",
    "            if (spend + costs) > coh:\r\n",
    "                return return_terminal(reason = 'CASH SHORTAGE',\r\n",
    "                    extra_reward=self.out_of_cash_penalty,\r\n",
    "                )\r\n",
    "\r\n",
    "            # verify we didn't do anything impossible here\r\n",
    "            assert (spend + costs) <= coh\r\n",
    "\r\n",
    "            # update our holdings\r\n",
    "            coh = coh - spend - costs\r\n",
    "            holdings_updated = holdings + actions\r\n",
    "            self.date_index += 1\r\n",
    "            state = (\r\n",
    "                [coh] + list(holdings_updated) + self.get_date_vector(self.date_index)\r\n",
    "            )\r\n",
    "            self.state_memory.append(state)\r\n",
    "            reward = reward * self.reward_scaling\r\n",
    "            return state, reward, False, {}\r\n",
    "\r\n",
    "    def get_sb_env(self):\r\n",
    "        e = DummyVecEnv([lambda: self])\r\n",
    "        obs = e.reset()\r\n",
    "        return e, obs\r\n",
    "    \r\n",
    "    def get_multiproc_env(self, n = 10):\r\n",
    "        def get_self():\r\n",
    "            return deepcopy(self)\r\n",
    "        e = SubprocVecEnv([get_self for _ in range(n)], start_method = 'fork')\r\n",
    "        obs = e.reset()\r\n",
    "        return e, obs\r\n",
    "\r\n",
    "    def save_asset_memory(self):\r\n",
    "        self.account_information[\"date\"] = self.dates[: len(self.account_information['cash'])]\r\n",
    "        return pd.DataFrame(self.account_information)\r\n",
    "\r\n",
    "    def save_action_memory(self):\r\n",
    "        return pd.DataFrame(\r\n",
    "            {\"date\": self.dates[: self.date_index], \"actions\": self.actions_memory}\r\n",
    "        )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(StockTradingEnvV2.__doc__)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "information_cols = ['open', 'high', 'low', 'close', 'volume', 'day', 'macd', 'rsi_30', 'cci_30', 'dx_30', 'turbulence']\r\n",
    "\r\n",
    "e_train_gym = StockTradingEnvV2(df = train, \r\n",
    "                              hmax = 100, \r\n",
    "                              out_of_cash_penalty=-1e6,\r\n",
    "                              daily_information_cols = information_cols,\r\n",
    "                              print_verbosity = 500)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# let's do multiprocessing with n_cores-1\r\n",
    "n_cores = multiprocessing.cpu_count() - 2\r\n",
    "print(f\"using {n_cores} cores\")\r\n",
    "\r\n",
    "\r\n",
    "env_train, _ = e_train_gym.get_sb_env()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "agent = DRLAgent(env = env_train)\r\n",
    "print(config.PPO_PARAMS)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ppo_params ={'n_steps': 128, \r\n",
    "             'ent_coef': 0.01, \r\n",
    "             'learning_rate': 0.00025, \r\n",
    "             'batch_size': 256, \r\n",
    "            'gamma': 0.99}\r\n",
    "\r\n",
    "policy_kwargs = {\r\n",
    "#     \"activation_fn\": ReLU,\r\n",
    "    \"net_arch\": [1024, 1024, 1024], \r\n",
    "#     \"squash_output\": True\r\n",
    "}\r\n",
    "\r\n",
    "model = agent.get_model(\"ppo\",  model_kwargs = ppo_params, policy_kwargs = policy_kwargs, verbose = 0)\r\n",
    "model = model.load(\"quicksave_ppo_dow.model\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data_turbulence = processed[(processed.date<'2019-01-01') & (processed.date>='2009-01-01')]\r\n",
    "insample_turbulence = data_turbulence.drop_duplicates(subset=['date'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "insample_turbulence.turbulence.describe()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def DRL_prediction(model, environment):\r\n",
    "    test_env, test_obs = environment.get_sb_env()\r\n",
    "    \"\"\"make a prediction\"\"\"\r\n",
    "    account_memory = []\r\n",
    "    actions_memory = []\r\n",
    "    test_env.reset()\r\n",
    "    for i in range(len(environment.df.index.unique())):\r\n",
    "        action, _states = model.predict(test_obs)\r\n",
    "        #account_memory = test_env.env_method(method_name=\"save_asset_memory\")\r\n",
    "        #actions_memory = test_env.env_method(method_name=\"save_action_memory\")\r\n",
    "        test_obs, rewards, dones, info = test_env.step(action)\r\n",
    "        if not dones[0]:\r\n",
    "            account_memory = test_env.env_method(method_name=\"save_asset_memory\")\r\n",
    "            actions_memory = test_env.env_method(method_name=\"save_action_memory\")\r\n",
    "        if dones[0]:\r\n",
    "            print(\"hit end!\")\r\n",
    "            break\r\n",
    "    return account_memory[0], actions_memory[0]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "trade = data_split(processed, '2019-01-01','2021-06-01')\r\n",
    "e_trade_gym = StockTradingEnvV2(df = trade,hmax = 10,initial_amount = 1000000,\r\n",
    "                              daily_information_cols = information_cols,\r\n",
    "                              print_verbosity = 500)\r\n",
    "\r\n",
    "df_account_value, df_actions = DRL_prediction(model=model,\r\n",
    "                        environment = e_trade_gym,)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_account_value.head(50)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "action_plot_df = df_actions.copy()\r\n",
    "action_plot_df['buy_sell'] = action_plot_df['actions'].apply(\r\n",
    "    lambda x: np.clip(x, -1, 1)[18])\r\n",
    "action_plot_df['actions'] = action_plot_df['actions'].apply(lambda x: x[18])\r\n",
    "action_plot_df = pd.merge(action_plot_df, trade[trade['tic'] == 'MSFT'], how='left', on='date')[\r\n",
    "    [\"date\", \"actions\", \"open\", \"buy_sell\"]]\r\n",
    "\r\n",
    "plt.figure(figsize=(20, 12))\r\n",
    "plt.plot(action_plot_df['date'], action_plot_df['open'],\r\n",
    "         linewidth=0.8, color='black')\r\n",
    "plt.scatter(action_plot_df.loc[action_plot_df['buy_sell'] == 1, 'date'].values, action_plot_df.loc[action_plot_df['buy_sell'] ==\r\n",
    "                                                                                                   1, 'open'].values, label='BUY', color='green', s=25, marker=\"^\")\r\n",
    "plt.scatter(action_plot_df.loc[action_plot_df['buy_sell'] == -1, 'date'].values, action_plot_df.loc[action_plot_df['buy_sell']\r\n",
    "                                                                                                    == -1, 'open'].values, label='SELL', color='red', s=25, marker=\"v\")\r\n",
    "\r\n",
    "plt.bar(action_plot_df['date'].values, action_plot_df['actions'].values,color='blue', alpha=0.5)\r\n",
    "plt.legend()\r\n",
    "plt.xlabel('Date')\r\n",
    "plt.ylabel('open price')\r\n",
    "plt.title('MSFT stock price with buy and sell signal')\r\n",
    "plt.show()\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_actions.to_dict(orient = 'rows')[:3]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"==============Get Backtest Results===========\")\r\n",
    "now = datetime.datetime.now().strftime('%Y%m%d-%Hh%M')\r\n",
    "\r\n",
    "perf_stats_all = backtest_stats(account_value=df_account_value, value_col_name = 'total_assets')\r\n",
    "perf_stats_all = pd.DataFrame(perf_stats_all)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"==============Benchmark our results against DJI===========\")\r\n",
    "\r\n",
    "%matplotlib inline\r\n",
    "backtest_plot(df_account_value, \r\n",
    "             baseline_ticker = '^DJI', \r\n",
    "             baseline_start = df_account_value.date.values[0],\r\n",
    "             baseline_end = df_account_value.date.values[-1], value_col_name = 'total_assets')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}